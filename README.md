# NJU-AIproject-CompanyEvaluation
本仓库是南京大学AI应用开发课程作业，实现了大模型对公司评价的加强
# 课题名称：基于Llamaindex框架实现RAG构建公司评价模型

## 一、课题背景：
本课题组成员主要由金融专业背景的学生构成。在日常的专业学习中，我们深度参与对A股上市公司的多维度分析，涵盖股价波动趋势解读、财务报表深度剖析、基本面价值评估等核心内容。这些实践不仅要求我们掌握扎实的理论知识，更亟需高效获取、整合并解读海量市场与公司信息的能力。

与此同时，团队多数成员正面临实习与就业的关键阶段。在职业选择过程中，我们深刻体会到，除了公开的财务和市场数据，深入了解目标公司的内部文化、发展潜力、员工口碑等"软性"信息同样至关重要。然而，这些信息往往散见于网络评论、新闻报道等非结构化文本中，难以系统化获取和分析。

基于上述双重需求——既服务于金融专业学习中对公司量化分析的深化，也服务于求职过程中对公司综合实力的定性评估——我们决定利用本次课题机会，探索大语言模型技术的应用潜力。我们的核心目标是：构建一个融合检索增强生成（RAG）技术的大模型系统。该系统将突破性地整合来自权威渠道的结构化市场数据、核心财务数据以及广泛分散的非结构化舆论评论，致力于打造一个智能化、多维度、可交互的公司评价与分析平台。我们期望该平台不仅能成为金融学习的有力辅助工具，提升研究效率与深度，更能为面临职业选择的同学提供全面、客观、深入的"公司画像"，服务于其精准求职决策。

---

## 二、创意说明：
本课题突破传统公司评价模型的单一维度局限，创新性地构建了金融-舆情双通道动态评估体系。区别于纯舆论分析的情绪化倾向或纯财务指标的静态缺陷，本模型深度融合课题组金融专业优势：一方面整合净利率、ROE等核心金融指标构建硬性评估通道；另一方面解析社交媒体的非结构化文本，生成软性舆情指数通道。二者融合使评价结论既具备金融严谨性，又反映社会感知力。

针对大语言模型的历史数据分析瓶颈，本系统依靠长周期数据关联引擎：在构建数据库时纳入近十年重大指标的时序数据，通过RAG技术实现跨时空因果推理。技术实现上，采用异构数据融合架构——以金融场景优化的检索策略精准打通结构化数据与非结构化数据，显著提升信息耦合效率，最终输出兼具历史纵深与实时动态的公司全景评估报告。

---

## 三、课题产品介绍：
本课题组项目产出为一个用于公司评价的智能对话系统，产品基于RAG（检索增强生成）大模型系统，能够从大量的数据中检索出与用户问题相关的知识和信息，为生成准确的回答提供依据。具备对公司财务状况、工作环境等专业领域的评估能力，能给出较为全面和深入的分析。

### 3.1 产品架构：
1. **客观财务数据整合**：系统全面覆盖公司结构化财务数据，诸如资产负债表、利润表、现金流量表等详尽且准确的财务报表数据，以及财务比率分析等衍生数据。
2. **非结构化数据赋能**：整合目标公司的内部文化、发展潜力、员工口碑等"软性"信息，通过员工评价等非结构化数据赋能系统。
3. **RAG技术驱动**：作为产品核心的RAG大模型系统，在面对用户提出的公司评价与分析问题时，系统首先精准理解用户意图，并从已整合的客观财务数据和非结构化的员工评价数据中快速检索出高度相关的知识内容。然后，基于这些知识素材，大模型开启智能生成模式，为用户提供便捷、专业、全面且个性化的分析报告、评价文本或决策建议。

### 3.2 产品优势：
1. **数据权威性与全面性**：整合的均为权威渠道的架构化财务数据，确保数据的可信度和准确性；同时，广泛收集非结构化舆论评论，拓宽信息来源范围，使对公司评价的视角更加多元、全面。
2. **智能化与精准度高**：借助RAG技术的强大能力，系统能够在海量数据中迅速检索出精准匹配的有用信息，并生成符合用户需求的高质量分析内容。
3. **适应性强与拓展性好**：本产品适用于多种用户场景和行业领域，涵盖金融投资、企业管理、行业研究还是商业咨询等。

### 3.3 使用场景：
1. **应届毕业生生求职**：为应届毕业生提供公司基本信息，辅助职业规划，匹配个人职业目标，帮助识别潜在的公司财务、工作环境风险，能够有效的减缓应届生就业困难的痛点。
2. **投资决策辅助**：为投资者提供全面、深入的公司基本面分析，以及公司内部员工评价等非财务数据，帮助投资者做出更加明智、准确的投资决策，规避投资风险，提高投资回报率。

### 3.4 举例：
**Q**：请评价一下贵州茅台的财务情况？

**A**：贵州茅台的财务情况表现非常优秀。其资产总计和流动资产在A股食品饮料行业中处于最高水平，其盈利能力、偿债能力、营运能力、成长能力等各项财务指标均表现突出，展现了较强的行业竞争力。此外，公司近几年的分红率维持在较高水平，显示出公司良好的盈利能力和现金流状况。2023年财报显示，公司实现营业收入约1380亿元（同比增长约15%），归母净利润约720亿元，同比增长约13%，业绩增长稳定。

**Q**：评价一下比亚迪的工作环境？

**A**：比亚迪的工作环境总体来说还可以，食堂和环境不错。配有超市和篮球场，适合散步。公司流程较多，但薪资和福利较好，公司管理严格，员工培训充分，适合长期发展。

---

## 四、技术实现路径：

### 4.1 爬虫数据获取
首先我们利用爬虫通过多模块协作实现职Q平台公司评价数据的采集，其中包括：

1. **请求管理**：使用 requests.Session 配合 HTTPAdapter 建立会话连接，设置重试策略，通过 np.random.choice(cookie) 随机选择 Cookie 并动态生成 User-Agent 以规避反爬
2. **数据解析**：利用 lxml.etree 提取页面中 script 标签内的 JSON 初始数据，通过 json.loads 解析公司基础信息，并构建详情页 URL
3. **分层爬取**：主函数 companyspider 抓取公司列表；companyspider2 进一步爬取公司详情页的评论数据，支持分页遍历直至数据为空
4. **异常处理**：对 JSON 解析失败、KeyError 等异常进行捕获，触发 10 秒延迟重试机制，失败时记录空数据到 DataFrame 并跳过当前任务
5. **数据存储**：使用 pd.concat 动态合并多批次数据到 CSV 文件，通过 company_breakpoint 实现断点续爬，正则模块 GenShortName/GenNickName 清理公司名称噪声字符，全程通过 tqdm 进度条监控爬取进度。

### 4.2 数据分析与处理
除了爬虫获取的公司评论数据，我们也调用了Wind的API，获取了对应公司的金融指标，包括收盘价、换手率、总市值、流动比率、速动比率、权益乘数等。接下来我们需要将数据进行合并并将数据转化为可以被LLM和Embedding模型接受的数据格式。数据分析流程主要基于Python的pandas库实现多源异构数据整合，技术实现包含以下核心环节：

1. 首先对原始金融指标数据进行缺失值处理与列名规范化，使用pd.merge()通过股票代码Stkcd进行多表关联，采用左连接确保数据完整性
2. 其次将股票基本信息表与市场交易数据通过Stkcd_filled字段进行精准匹配，运用rename()方法统一字段命名规范；针对性能数据表则通过apply()方法生成唯一标识ID，构建"股票代码+简称+全称"的三元组主键
3. 最后通过自定义mer_json()函数实现JSON格式数据的深度合并，采用字典推导式进行ID匹配与字段聚合，并利用tqdm进度条监控大规模数据合并过程，确保金融指标、市场数据与文本评论数据在时间和空间维度上的对齐，为后续的量化分析与自然语言处理建立高质量数据底座。

### 4.3 Llamaindex框架的选取
在讨论如何实现目标时，我们主要聚焦于技术方案的选择：RAG、微调或两者结合。最终，我们决定仅采用RAG。这一决策主要基于两点：一方面，由于算力限制和标注耗时等因素，微调短期内难以实现；另一方面，微调本身也不适用于我们的目标场景。我们的数据库并非高度私有化数据，通用LLM通常已涵盖相关信息。此外，我们要求模型能提供精准且专业的定向回答，RAG因此成为更理想的选择。确定采用RAG后，我们选择了当前效率较高的RAG框架——Llamaindex。

### 4.4 AutoDL远程服务器租用
为了满足更好的硬件需求以及组内成员合作方便，我们的工程选择在AutoDL租用的远程服务器上进行。

### 4.5 模型的选取
在选择LLM时，我们面临两个选项：本地部署Qwen1.5-7B-Chat模型或调用OpenAI API。最初，我们认为本地部署大模型更具稳定性，于是从ModelScope平台部署了该模型。然而，实际运行效果不佳，主要表现为响应速度缓慢且回答准确性不足。在排除其他干扰因素后，我们确定问题源于该模型本身的理解能力有限。鉴于我们无法在本地部署更大、更强的模型，最终我们选择调用OpenAI的GPT-3.5-turbo API，这一调整显著提升了响应速度和回答准确性。

在 Embedding 模型的选择上，我们设定了几个关键标准：轻量级、对中文支持良好、以及稳定性高。基于这些标准，我们最终选用了由北京智源人工智能研究院开发的 bge-small-zh-v1.5 模型。该模型具有 512 维的向量输出，对中文任务适配性优秀。此外，该模型体积较小，资源占用低，便于部署。

### 4.6 向量数据库的构建
最初我们选用简单易用、部署便捷的ChromaDB作为向量数据库，但在实际运行中发现检索耗时过长，分析原因在于数据集庞大且信息复杂，而ChromaDB更适合小型数据场景。因此，我们改用Milvus作为向量数据库。Milvus在大规模向量数据存储和检索方面表现出色，替换后检索时间显著缩短，其性能卓越且整体运行效果极佳。Milvus 是一款开源的向量数据库，专为处理海量向量数据而设计。它支持多种索引类型，可存储和检索数十亿甚至数万亿个向量点。其功能强大，支持向量与标量的结合查询，满足复杂检索需求。Milvus 性能卓越，能在高并发场景下保持低延迟，广泛应用于推荐系统、语义搜索等领域，是大规模向量数据处理的理想选择。

### 4.7 Streamlit前端构建
对于应用类产品而言，提供交互式 Web 界面不可或缺。然而，考虑到团队当前缺乏 Web 开发经验，我们最终选择了 Streamlit 框架。该框架能以极简的方式构建 Web 应用：开发者仅需编写 Python 脚本，并通过添加其特定组件定义交互逻辑，即可将脚本高效转化为功能完善的交互式应用。
