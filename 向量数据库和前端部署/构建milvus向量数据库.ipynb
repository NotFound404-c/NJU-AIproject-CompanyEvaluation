{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7be683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from llama_index.core.schema import TextNode\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import os\n",
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex, StorageContext, Settings\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import PromptTemplate\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "import torch\n",
    "import pandas as pd \n",
    "import json\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-R55EltjXK0FAaHbqhPV1OHtWifZXEBJRbDXQS4JZUk4uxwvo\"\n",
    "# os.environ[\"OPENAI_API_BASE\"] = \"https://api.shubiaobiao.com/v1\"\n",
    "# openai.api_key = \"sk-R55EltjXK0FAaHbqhPV1OHtWifZXEBJRbDXQS4JZUk4uxwvo\"\n",
    "# openai.base_url = 'https://api.shubiaobiao.com/v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e87af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv(), verbose=True)  # 读取本地 .env 文件，里面定义了 OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8230a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "URI = \"./milvus_filter_demo.db\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9726cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/vitol/vscode/firm_perf/firm_perf_code/转JSON/json文件汇总/merged.json', 'r', encoding='utf-8') as file:\n",
    "\n",
    "    json_list = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecea40d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nodes(raw_data: List[Dict]) -> List[TextNode]:\n",
    "    \"\"\"添加ID稳定性保障\"\"\"\n",
    "    nodes = []\n",
    "    for entry in raw_data:\n",
    "        j2str = []\n",
    "        content_str = json.dumps(entry['text'],ensure_ascii=False)\n",
    "\n",
    "        id_e = entry[\"id\"]\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            node = TextNode(\n",
    "                    text=content_str,\n",
    "                    id_=id_e,  # 显式设置稳定ID\n",
    "                    metadata={\n",
    "                        \"公司全称\": entry['text']['公司全称'],\n",
    "                        \"公司简称\": entry['text']['公司简称'],\n",
    "                        \"股票代码\": entry['text']['股票代码'],\n",
    "                        \"行业分类\": entry['text']['申万行业分类'],\n",
    "                    }\n",
    "                )\n",
    "            nodes.append(node)\n",
    "        except Exception as e:\n",
    "            print(entry['id'][:9])\n",
    "            node = TextNode(\n",
    "                    text=content_str,\n",
    "                    id_=id_e,  # 显式设置稳定ID\n",
    "                    metadata={\n",
    "                        \"股票代码\": entry['id'][:9],\n",
    "                    }\n",
    "                )\n",
    "            nodes.append(node)\n",
    "            continue\n",
    "    \n",
    "    print(f\"生成 {len(nodes)} 个文本节点（ID示例：{nodes[0].id_}）\")\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab5c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = create_nodes(json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f0e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = OpenAI(\n",
    "#     api_key=\"sk-R55EltjXK0FAaHbqhPV1OHtWifZXEBJRbDXQS4JZUk4uxwvo\",  # 替换为您的API密钥\n",
    "#     base_url=\"https://api.shubiaobiao.com/v1\"  # 替换为您的代理URL\n",
    "# )\n",
    "# def get_embeddings(texts, model=\"text-embedding-ada-002\", dimensions=None):\n",
    "#     '''封装 OpenAI 的 Embedding 模型接口'''\n",
    "#     if model == \"text-embedding-ada-002\":\n",
    "#         dimensions = None\n",
    "#     if dimensions:\n",
    "#         data = client.embeddings.create(\n",
    "#             input=texts, model=model, dimensions=dimensions).data\n",
    "#     else:\n",
    "#         data = client.embeddings.create(input=texts, model=model).data\n",
    "#     return [x.embedding for x in data]\n",
    "# test_query = [\"测试文本\"]\n",
    "# vec = get_embeddings(test_query)[0]\n",
    "# print(f\"Total dimension: {len(vec)}\")\n",
    "# print(f\"First 10 elements: {vec[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729fadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from pymilvus import model\n",
    "\n",
    "# openai_ef = model.dense.OpenAIEmbeddingFunction(\n",
    "#     model_name='text-embedding-ada-002',\n",
    "#     api_key='',\n",
    "#     base_url='https://api.shubiaobiao.com/v1'\n",
    "# )\n",
    "# embed_model = OpenAIEmbedding(\n",
    "#     model=\"text-embedding-ada-002\",\n",
    "#     base_url=\"https://api.shubiaobiao.com/v1\",\n",
    "#     api_key=\"\"\n",
    "# )\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "        model_name=r\"/Users/vitol/vscode/firm_perf/firm_perf_code/embed\"\n",
    "    )\n",
    "vector_store = MilvusVectorStore(\n",
    "    uri=URI,\n",
    "    # token=TOKEN,\n",
    "    collection_name=\"companyinfo\",  # Change collection name here\n",
    "    dim=512,  # Vector dimension depends on the embedding model\n",
    "    overwrite=True,  # Drop collection if exists\n",
    "\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304dfc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex(nodes, storage_context=storage_context,embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import (\n",
    "    MetadataFilter,\n",
    "    MetadataFilters,\n",
    "    FilterOperator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d259195",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(similarity_top_k=1)\n",
    "result_nodes = retriever.retrieve(\"平安银行\")\n",
    "\n",
    "for node in result_nodes:\n",
    "    print(node.text)\n",
    "    # print(node.metadata)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30912e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from llama_index.core.schema import TextNode\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import os\n",
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex, StorageContext, Settings\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import PromptTemplate\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "import torch\n",
    "import pandas as pd \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7735ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from pymilvus import model\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "        model_name=r\"/Users/vitol/vscode/firm_perf/firm_perf_code/embed\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b450f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "URI = \"/Users/vitol/vscode/firm_perf/firm_perf_code/转JSON/合并json code/milvus_filter_demo.db\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab92cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e170374",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MilvusClient(uri=URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d3817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新连接到现有的向量存储\n",
    "vector_store = MilvusVectorStore(\n",
    "    uri=URI, \n",
    "    dim=512,\n",
    "    collection_name=\"companyinfo\",\n",
    "    overwrite=False  # 设置为 False 以使用现有集合\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_vector_store(vector_store,embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919be91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import (\n",
    "    MetadataFilter,\n",
    "    MetadataFilters,\n",
    "    FilterOperator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df148303",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(similarity_top_k=1)\n",
    "result_nodes = retriever.retrieve(\"平安银行\")\n",
    "\n",
    "for node in result_nodes:\n",
    "    print(node.text)\n",
    "    # print(node.metadata)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1797cd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# 创建 LlamaIndex 的 OpenAI LLM 实例\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_base='https://api.shubiaobiao.com/v1',\n",
    "    api_key=''  \n",
    ")\n",
    "response = llm.complete(\"Hello, how are you?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf3824",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# 创建 LlamaIndex 的 OpenAI LLM 实例\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_base='https://api.ai-gaochao.cn/v1',\n",
    "    api_key=''  \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 在查询引擎中使用这个 LLM\n",
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    similarity_top_k=1\n",
    "    )\n",
    "res = query_engine.query(\"平安银行注册地址？\")\n",
    "print(res)\n",
    "\n",
    "iface = gr.Interface(fn=chat_with_robot, inputs=\"text\", outputs=\"text\", title=\"我的吐槽机器人\")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de005e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import streamlit as st\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "from llama_index.vector_stores.milvus.utils import BM25BuiltInFunction\n",
    "from pymilvus import MilvusClient\n",
    "\n",
    "# 初始化组件\n",
    "@st.cache_resource\n",
    "def init_query_engine():\n",
    "    # 创建 LlamaIndex 的 OpenAI LLM 实例\n",
    "    llm = OpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        api_base='https://api.ai-gaochao.cn/v1',\n",
    "        api_key=''  \n",
    "    )\n",
    "    \n",
    "    # client = MilvusClient(uri=\"milvus_filter_demo.db\")\n",
    "    # 连接到本地 Milvus Lite（sqlite 文件）\n",
    "    # 注意：uri 需要用 sqlite:/// 前缀，且路径要绝对路径\n",
    "    vector_store = MilvusVectorStore(\n",
    "        uri=\"./milvus_filter_demo.db\",\n",
    "        collection_name=\"companyinfo\",\n",
    "        dim=512,\n",
    "        overwrite=True,\n",
    "    )\n",
    "    \n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    index = VectorStoreIndex.from_documents([], storage_context=storage_context)\n",
    "    \n",
    "    # 创建查询引擎\n",
    "    query_engine = index.as_query_engine(\n",
    "        llm=llm,\n",
    "        similarity_top_k=1\n",
    "    )\n",
    "    \n",
    "    return query_engine\n",
    "\n",
    "# Streamlit 界面\n",
    "st.title(\"智能问答系统\")\n",
    "st.write(\"基于 Milvus 和 LlamaIndex 的 RAG 系统\")\n",
    "\n",
    "# 初始化查询引擎\n",
    "try:\n",
    "    query_engine = init_query_engine()\n",
    "except Exception as e:\n",
    "    st.error(\"Milvus 连接失败，请检查本地数据库文件路径和权限。错误信息：{}\".format(str(e)))\n",
    "    st.stop()\n",
    "\n",
    "# 用户输入\n",
    "user_question = st.text_input(\"请输入您的问题：\", placeholder=\"例如：平安银行注册地址？\")\n",
    "\n",
    "if st.button(\"提交\") and user_question:\n",
    "    with st.spinner(\"正在查询...\"):\n",
    "        try:\n",
    "            # 执行查询\n",
    "            response = query_engine.query(user_question)\n",
    "            \n",
    "            # 显示结果\n",
    "            st.success(\"查询完成！\")\n",
    "            st.write(\"**回答：**\")\n",
    "            st.write(response)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # 针对 Milvus 连接失败的报错做特殊提示\n",
    "            if \"Fail connecting to server on localhost:19530\" in str(e):\n",
    "                st.error(\"Milvus 连接失败，请确认您使用的是本地 Milvus Lite（sqlite 文件），而不是需要启动服务的 Milvus Server。\\n\"\n",
    "                         \"如需使用本地 sqlite 文件，请确保 uri 以 sqlite:/// 开头，且文件路径正确。\\n\"\n",
    "                         \"原始错误信息：{}\".format(str(e)))\n",
    "            else:\n",
    "                st.error(f\"查询出错：{str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da105090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "# 使用系统临时目录，通常有读写权限\n",
    "temp_dir = tempfile.gettempdir()\n",
    "db_path = os.path.join(temp_dir, \"milvus_filter_demo.db\")\n",
    "db_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firm_judgement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
